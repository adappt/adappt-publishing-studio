[{"nid":"1342","text_data":"adappt studio  Perfect Solution for Your Business"},{"nid":"1379","text_data":"CMS Features"},{"nid":"1380","text_data":"Content Types"},{"nid":"1381","text_data":"Ckeditor"},{"nid":"1382","text_data":"Content Management    Adding Contents in the CMS     You can add\/create pages in the CMS by selecting \u201cBook Page\u201d from the \u201cContent\u201d Menu -&gt; Add content A Book page is nothing but a simple page comprising of text\/images\/tables in your mobile app. Various content types are present in a Book Page for multiple purposes.  Many book pages inter linked, form a book or a complete Reaction mobile application."},{"nid":"1383","text_data":"Json Data"},{"nid":"1384","text_data":"Mobile Features"},{"nid":"1385","text_data":"Press Releases"},{"nid":"1386","text_data":"Case Studies"},{"nid":"1387","text_data":"The killer feature of Angular 2  In some circles Javascript has a reputation as a kids language with a capacity to create horrendous unmaintainable spaghetti code. The next version of Javascript ES6 goes a long way to addressing that with much stronger object orientation standards, and in the last few years, many issues have been addressed. Supporting frameworks such as Ember, Angular, Typescript, Cordova, Coffeescript have all contributed to a maturing of Javascript. One thing is clear, Javascript is far closer to achieving the dream Java chased of a single language that works on all platforms.  I recently worked with one of our junior developers to refactor some code. The code in question creates live charts. The refactored code was 60% smaller. We took all of the logic out of the rendering modules and moved it to re-usable data preparation services.  Separating logic and presentation layers makes code easier to read, it also makes it faster, slimmer and easier to build on. This simple principle is one of the cornerstones of AngularJS         The Challenge, the solution and the cost:    The challenge is how do we separate \/ abstract the data controllers and presentation layers. The solution Angular offers is data-binding. With full data-binding we can create a data layer and a separate presentation layer. We can structure our code in such a way that it focusses the controller logic on manipulating the data, whilst leaving the presentation layer to update itself.  In practice this means that we can place all our attention on updating the data. We can create complex data objects with dynamic computations and focus on keeping our data structures updated, whilst data-binding means that our presentation layer updates itself. This approach works incredibly well and is a one of Angular\u2019s great features, but it does have a problem.  The problem is that with large complex objects and arrays, or even arrays of objects containing arrays, how does the presentation layer know when a particular piece of data has changed.  Let\u2019s look at a typical example. Imagine you are working on a platform and you realize your name is misspelled. Instead of seeing Veronica you see Veronicca in the header bar. Once you have been to your profile and updated your name, you expect the header to update and show your corrected name. Angular data binding will do this, but in the Angular 1 this was done by running a digest cycle that checked whether data had changed on each cycle. Once we have a lot of data, the processor cost of making sure your name is updated correctly becomes very expensive in terms of CPU usage.  The Angular 2 solution is a complete revamp of the way data is observed and by massively increasing performance it opens up huge possibilities for the complexity and amount of data we can automatically bind to our display.  The down and dirty technical is below:  Angular maintains a tree of \u201cchange detectors\u201d, one per component\/directive. The change detectors are created when Angular creates components and keep track of the state of all bindings.  Compared to Angular 1, the change detection graph is a directed tree and does not have cycles, and this makes Angular 2 much faster.  When an event fires, the event handler callback can update whatever data it wants to\u200a\u2014\u200athe shared application model\/state and\/or the component\u2019s view state. After that, the hooks then run Angular\u2019s change detection algorithm. Every component in the tree is examined from the top, in depth-first order. For any binding changes that are found, the Components are updated. The browser reacts to the DOM changes and accordingly changes the display.  In summary the killer feature of Angular 2 is speed. With more speed we can create more powerful apps, and with increased performance we can realize the true potential of full data-binding."},{"nid":"1388","text_data":"10 awesome features of NodeJS  When I first started learning Neural Networks like everybody else I used Python, but these days I use NodeJS. Here are some of the reasons why?         Non-blocking thread execution = Massive speed gains    Perhaps it\u2019s greatest feature is its least understood by those who are considering it and rookies. Non blocking means that whilst we are waiting for for a response for something outside of our execution chain eg loading some data, reading from a database or polling a remote service, we continue executing the next tasks in the stack. This concept is revolutionary and make NodeJS extremely fast and efficient. When it comes to code in loops this is particularly relevant. For example if we have to load 50 chunks of data and each one takes 50ms, in traditional linear execution that would be 50x50 = 2.5 seconds. NodeJS will fire off all of those requests straight away so all those requests go out in parallel and are handled when they return. Typically making 50 requests might take less than 1ms so are time to fetch 50 requests might be &lt;51ms.    Multi Threaded    One of the most common complaints by people who do not understand node JS is that it is single threaded and if you have an core CPU it will only run on one core. Nothing could be further from the truth, and is another case of \u201cfake news\u201d. In tandem with its non blocking architecture multithreaded apps are also highly efficient.  Node.js is non-blocking which means that all functions ( callbacks ) are delegated to the event loop and they are ( or can be ) executed by different threads. That is handled by Node.js run-time. Node.js does support forking multiple processes ( which are executed on different cores ). It is important to know that state is not shared between master and forked process. We can pass messages to forked process ( which is different script ) and to master process from forked process with function send.    Cross Platform    Move aside Java, NodeJS is not only cross platform, but when developed with the correct structure can be packaged into an executable containing all its own dependencies.    Build Vs Complie = Significantly faster development environment    If you are a developer who likes to check their code as they go then being able to see your code running in under a second vs 30 seconds + for .net and java equivalent scale systems is a game changer in terms of speed of delivery.    Object Oriented    A huge complaint against NodeJS was down to its JavaScript heritage, which frequently involved lots of procedural spaghetti code. Frameworks like CoffeeScript and TypeScript solved these issues, but came as a bolt on for those who seriously cared about coding standards. Now with the release and general adoption of ES6, Classes are built into the framework and the code looks syntactically similar to C# , Java and SWIFT.    Synchronous code execution    Non blocking code execution is conceptually more difficult to code than code that runs in a straight line, because we have blocks of code hanging around waiting for asynchronous events to return. Whilst those blocks are waiting to execute maybe some of our variables have changed values eg for our code that fetches 50 pieces of data the index counter will count from 1 to 50. In straight line coding the counter would be at 1 when the first piece of data returns and 10 when the 10th piece of data returns. In our non blocking environment we fired all the calls off as quickly as we could rather than waiting for one to finish before we fired the next. THAT IS A HUGE GOTCHA FOR NOOBS because the counter is sitting at 50 for every returning piece of data (since it got to 50 at light speed). Most NodeJS noobs fail at this point because they do not understand why their code has failed.    Over 6000,000 free open source packages on npm    The Node community is enormous and the number of permissive open source projects available to help you save time is mind boggling. These libraries range from simple helpers and charts to full blown frameworks.    Create both SASS, service and desktop platforms    Whilst originally a cloud web solution, there was pretty rapidly a demand for NodeJS to be usable in desktop applications. The ElectronJS project bridges this gap, amd many common apps are based on electron including Slack, Visual Studio Code, Discord, Skype and many more.  \u00a0    Being Based on Javascript Means Frontend and Backend Developers use the Same Language    Back in the last millenium, backend developers earned many times more than frontend developers and frequently would avoid frontend code in the same way one might avoid a steamy dog mess on the pavement. However the world moved on and people started to realise that rather than slowing the experience down by preparing everything on the backend server it was possible to use the backend server to send the data and leverage the power of HTML5 browser rendering. Having the backend and frontend skillsets merged,buts the brightest minds working together instead of pulling in different directions.  \u00a0    Sockets and Two Way Data Binding    Most of the web is based on a system of request and response. i.e. I ask for a page and the server sends me a page. The early chat apps used to used something called a poll, where they simply asked every second - \u201care there any new messages\u201d. This approach clearly sucked, and sockets stepped into the gap. Sockets allows a server to broadcast messages to all clients connected a specific group. Not only that but sockets allow on client to broadcast (via the server) to a whole group. Great for chat groups, and even better for data binding. If one user changes some data, all the other users can be updated in milliseconds. Whilst other languages do have socket libraries, NodeJS has an advantage because of its event driven non blocking architecture, which makes it ideally suited to handle sockets. NodeJS was the first to do it well and still does it better than any other framework."},{"nid":"1389","text_data":"AI helped promote a developer to technology director  Since I have far too many recruitment consultants in my connections list, I am going to call this employee Bill (his real name rhymes so anyone who knows us will know who I mean). Bill is very modest and utterly charming, his team adore him and his academic accomplishments include a First Place in his State Level Mathematics rankings in 2000. If he turned his mind to it he could hire his services out to the highest bidder and live a life most can only dream of. Instead he chose to join a small startup in Pondicherry and work on projects that make a difference to the world such as the World Health Organisation Global Outbreak and Response Network.       We use an\u00a0 employee monitoring \u00a0platform\u00a0 https:\/\/knowyourday.ai \u00a0as part of our flexible working program. KnowYourDay uses AI to categorise staff and help improve effective working habits. Typically the system can place staff with 90% + accuracy, but when the system fails to understand a user\u2019s activity, it is a sign that something is wrong and intervention is needed. When the KnowYourDay looked at Bill, he did not fit the expected developer profile which raised eyebrows.  There are many reasons why someone might not classify correctly, for example if an analyst like Edward Snowden started to be classified as a dev-ops backup operator it certainly might warrant further investigation. Someone might classify differently because they are struggling or maybe they are not being well managed.  With Bill there was never any question of anything untoward, and no questions about his skill level or coding quality. The only question was why the Neural Network thought he was different to the other developers.  The results of the deeper analysis revolutionised the entire development process for the company. It turned out Bill did not match the other developers because Bill was actively using the software he worked on as part of his test regime. The topic was brought up at the monthly senior management meeting and the conclusion was other developers needed to work more like Bill than the other way around. The change in approach led to a significant increase in productivity and coding standards.  Within six months the rest of the team were more closely matching Bill\u2019s profile, whilst Bill himself has been promoted to Company Director, where he now heads up a cyber security interface project.  It is possible Bill may never have raised his own hand to seek a promotion given his modest unassuming nature. In his case an AI package spotted he was different and helped him gain a well deserved promotion."},{"nid":"1390","text_data":"We Ran an Internal Deep Learning Competition And This Is What Happened  Like most companies we have big logs of every site ever visited by our staff. Big brother or common sense is a different debate -\u201cguns don\u2019t kill people rappers do\u201d.  The prize was financial and of course a lot of kudos. These were the rules:    Out of work hours only.  Flexible teams  Two week deadline.    Our aim was to train a neural network which can accurately predict the departments \/ roles of people based on website logs.    And we had some mind blowing\u00a0results!        Senior management did not realize that they had given the development teams cart-blanche to expose their online Shopping and Social Networking during office hours.      The Neural network turned out to be able to accurately classify the majority of people by department with over 99% accuracy and with a blind test of humans doing the same the accuracy was less than 50%      The anomalies (people who did not fit the expected patterns of behaviour) were more revealing than the matches.        Results from our teams      Team one : Classified the data with high accuracy and represented it using radial histograms.               Vector based website classification               Neural Network based classification of\u00a0people    From team 1, only two people were incorrectly classified. The first person, it turned out the neural network was right and she was actually working as an analyst although we thought she was doing QA. The second person was out of tasks and hiding quietly. We had not realized, but the neural network did!    Team two: Created some of the most beautiful representations of the data and their classification network was both highly accurate and easy to read.             \u200b\u200b\u200b\u200b\u200b\u200b\u200b          Team three: Created the easiest to follow information and had the most accurate Neural Net.      User activity per\u00a0hour\u200b\u200b\u200b\u200b\u200b\u200b\u200b               User groups, eg. Job\u00a0seekers\u200b\u200b\u200b\u200b\u200b\u200b\u200b    They also shone the brightest light on behaviour such as start and end of the active day and browsing of none work related sites. Which underlines the point it is not just managers who care who is putting the hours in. Hard working staff are also very conscious of who is and who is not pulling their weight\u200a\u2014\u200aespecially regarding senior management.    Team four: Took a long range view of the data, which was a real eye opener vs a simple 3 day snapshot and created a simple intuitive way to understand the information.               Team five: has never worked on AI before but were mobile experts and decided to turn their hands to this competition.    The results were beyond what any of us could have expected because they moved outside of the box in their representations    \u200b\u200b\u200b\u200b\u200b\u200b\u200b  We were left us with an impossible choice for judging the winners.  At the end of this, what is fascinating is the use of AI to discover who is not behaving as we expect, which can have many reasons    Over achievers  Under achiever  Working \/ acting outside their remit (malicious \/ unintentional)    The next challenge for the team is scaling this, from being able to track a small company to being able to track and represent tens or even hundreds of thousands of staff, and in a way that is still easy to visualise and drill down.  As companies grow it is not possible to know everyone individually, but using a dedicated neural network for that task can provide a powerful solution to catching problems early, identifying best potential and visualising staff."},{"nid":"1391","text_data":"AI Suggestion Engines       If I could predict what you wanted before you walked into my shop, I could make sure I had it in stock when you arrived and sell it to you.  Imagine as a skateboarding geek in a world where geeks are back in fashion, you scoot into the comic store and the nerd behind the counter offers you a 1995 Spiderman 59. Not only does the owner know you well enough to know what is missing from your collection, they have actually kept it behind the counter just for you!!!  This kind of predictive recommendation is the Holy Grail of many long tail sales models. A predictive engine that can figure out what you will buy and have it ready and waiting for you, when you step through the door \/ open your browser.  AI predictive suggestion engines are can be irritating when they get it wrong, they may even seem quite trivial, but a group of companies are silently becoming extremely wealthy and running rings around the competition by doing this well. So what tools are available and how are they doing it?    History as a predictor of the future \u00a0- for the last three days you have lived off delivery pizza, including cold leftovers for breakfast. Now our predictive analytics engine steps up suggests what you should eat tonight. By looking at your history, our engines knows exactly what you like, and oh dear it looks like pizza for you again tonight....    Classification and similarity clustering \u00a0(Item Hierarchy) - Mmm ok lets agree that we do like Pizza, but not every night and try that again. By grouping \/ clustering similar types of food together our predictive recommendation engine knows that you are a Garlic Bread and Cheese person. We seem to be stuck in a rut, surely we can do better ...    Product and trending popularity \u00a0- seems that you are looking for better suggestions, so rather than studying you, we can look at everyone else to see what is popular right now. Curry is very popular tonight so our engine is going to suggest a nice Tikka Masala.    Profiling you \u00a0- hopefully we had a win with the curry, and hey if we did not get that right then we just learned that maybe you do not like spicy food. When it comes to profiling, all information can be useful. So we are going to start collecting everything we can, likes, dislikes, sex, age, where you live and as much of your browsing history as we can get. We will use this to categorise you with similar people and then look at what is popular and trending in your profile group.    Putting it all together with AI \u00a0- So we are going to look at your history, your profile, how much you spend and cluster you with similar people. We are also going to cluster our food together, and look at what is trending. We put all that together, but it is starting to get complicated, not least because all this data changes on a daily basis. We need supervised learning that can keep up with the the growing flow of information.  At this point we do need to get technical. We have all of this information and maybe if we sit teams of people to sift through it we could really make some smart suggestions, but if we want to do it without teams of analysts we need AI. Let's look below at what tools are on offer.    Meet LDA and SVD      LDA short for Latent Dirichlet Association    LDA is easiest to understand with a practical example analysing the following sentences    I ate an orange and peach smoothie for lunch  I like to eat cheese and chocolate.  Puppies and lambs are cute.  My friend bought a puppy today.  Look at this pretty chinchilla eating a piece of pie.    LDA is a way of identifying the topics in these sentences.  Sentences 1 and 2 are about food (Topic A)  Sentences 3 and 4 are about animals (Topic B)  Sentence 5 is about animals and food (Topic A and Topic B)  So LDA is a way of us breaking down free text into manageable taxonomies automatically without having to pre-create the taxonomy first.  LDA actually goes a step further, and as well as creating the categories it counts the words and assigns weights \/ percents to the categorisation. eg sentence 5 is 66% about food since there are two food related words to the one animal word.    SVD short for singular-value decomposition    Once we have mapped our information into vector space we end up with some pretty complex and large n-dimensional matrices which are mostly composed of zeros. Without going into the heavy maths SVD allows us to reduce the large multidimensional matrices into a simpler representations, which are still suitable for processing through a neural network    Factorisation Machines    Factorisation Machines are on the cutting edge when it comes to recommendation machines. They are currently the most effective and powerful engines we have at predicting what to suggest to you based on all of the above. When it comes to real life, these are the algorithms that are most successful.  In essence a Factorisation Machine is a supervised learning algorithm that can be used for for both classification and regression tasks.  Factorization machines were introduced by Steffen Rendle in 2010. The idea is to model interactions between features, ie taking all the things we know you like or dislike and then filling in the blanks where we do not have data.  The problem with pre FM models is that we have plenty of metadata, but we are not able to utilise that data effectively, with FM no training examples are required in the model parameters, making the models much more compact. In essence pre FM the data is still too big. The problem is that we are battling large scale sparse data sets i.e. most of our data is packed with zeros. The more categories we create the more zeros we have. Factorisation reduces the tensors by an order and prevents them from scaling out of control as the range of inputs increase.    Summary    Predictive engines are increasingly giving the giants like Netfllix and Amazon a huge edge, but these techniques are available to smaller companies too, and their applications range far and wide. When it comes to making the most of these technologies its starts with first knowing what is the possible, and hopefully this introduction will give you some ideas.    Footnote      https:\/\/KnowYourDay.ai  have been developing Neural Nets for behavioural analytics and corporate optimisation. Please contact me if you would like to know more."},{"nid":"1392","text_data":"Fat Cats, Fat Fingers and Personas  Many years ago I remember being a humble shift engineer and setting up the projector screen in the boardroom, whilst the producers and directors sat around with their feet on the table eating nibbles, and debating caricatures of viewers. As I ate my packed lunch I was a mixture of envious, dismissive and curious. What an easy life pretending to work and eating finger food.       This week we have been running one day workshops for some new projects we are starting and 30-40% of the workshops have been spent discussing personas.    Am I just living the dream of cushy meetings or does this have real value?    The honest truth is it has value beyond anything I could ever have imagined as a young engineer. The sheer amount of pain we have saved over the years by agreeing personas before we start coding, far outweighs all of the other decisions, such as choice of technology.  This reason is because choosing the right technology can only be done effectively when you understand who your audience are. Sounds obvious when you put it like that, but you would be amazed how many people are wedded to a single technology approach and start coding with the blind hope that \"this project will run smoothly\".    So how do we do personas?    There are many ways of doing this, some people base personas on real or facsimiles of real people, some create cartoon characters and we tend to do a mix.  For mobile apps we might create a persona as    The \u00a0 fat cat with fat fingers - \u00a0someone who expects to get key information in under 90 seconds and cannot be bothered to read help files or click small buttons. They engage best with big signposted buttons.  It is important to realise with humour aside, this is not a derogatory description, this is a legitimate user with a real need. The fat fingers are just a way of reminding us to keep it simple, and the fat cat description signifies this user is an influencer.    How Not To Do It    So perhaps the biggest mistake people make, is thinking we should identify our typical user and that everything must be aimed at that one user. We often create around four personas and our goal is to keep all personas happy.  So next to our fat cat we might also have an implementor and a researcher. Whilst the fat cat may only spend 90 seconds on the app, our researcher may sometimes spend 90 seconds for a quick lookup or 15-20 minutes if they are learning or researching.  So whilst the goal is not to be all things to all people, it is most definitely to keep ALL our key personas happy.  \u00a0"},{"nid":"1393","text_data":"Order Outline  Each book has a menu called \u201c Order Outline \u201d attached to it. Users with proper permission can view a list of all published books and its pages on the order outline page. Using this feature you can edit or delete pages or sections, change their titles, or change their weight (thus putting them in a different order)."},{"nid":"1394","text_data":"Tags  Tags is the most useful and important feature in the CMS. When you have enormous pages of contents, it becomes difficult for you to organize the relationship between the articles. For example if you wanted to show the related content of an article you must keep track of all the pages and its information and find a way to pick them and show that below an article.    How to create Tags?       First create the Tags Go to menu  Structure -&gt; Taxonomy -&gt; Tags -&gt; Add Term    While creating book page (Contents and Content MenuList), you can find a Tags drop down box. The tags you created will be listed there.  Choose appropriate tags for the page you create.  Multiple pages can be tagged under a Tag name.  Now in the mobile application you can see all the pages that were tagged will be listed under the Tag name(as Heading) below the article."},{"nid":"1395","text_data":"Translation  The Content management System allows to translate the content of a page in all major International languages. Once done, the React mobile applications will show the user the options to switch between languages.    How to translate a page:      As a first you need to enable the preferred language in the CMS backend for example \u201cFrench\u201d.  Go to the already created node\/page with texts and click \u201cTranslate\u201d tab.\u00a0  Click \u201cAdd Translations\u201d next to French language.  Now you are navigated to create a new French content for that particular node.  You can either choose \u201cContent\u201d and input titles and body texts in French or choose \u201cMirror Content\u201d and call a already created \u201cOriginal content\u201d in French.  By this way, each node can be translated to your preferred language.  If only few pages are translated in French will you switch to the French language in the mobile application. The remaining pages which are not translated and will show the default language which in our case is \u201cEnglish\u201d."},{"nid":"1396","text_data":"Derivedata - Scraping, Natural Language Extraction And Monitoring    The Overview:      Derivedata \u00a0is the hub empowered robust platform which does continuous monitoring of different kinds of websites (HTML, RSS, AJAX, Angular, React etc.) and delivers structured information in the form of API.    (1)        Users are provided with value added information in the form of content metadata within the API.    The platform has a simple dashboard which enables system administrators to receive email alerts and statistics for rendering reports and charts.    The Process:           The Requirement:    To design a page monitoring and extraction system which can monitor and scrape data from websites, providing useful information.  The platform should be able to deliver information instantly as and when its published in the websites.  The system should be able to notify administrators with email alerts in case the configured threshold is exceeded.    The Challenge:      Creating separate queues for every section in rabbitmq and checking the queues based on the time interval for extracting.  Initial spider collecting with sockets connection.  Working with Ajax\/Onclick\/Authentication sites.  Checking index pages for every 10 mins and discovering new spiders.  Extracting PDF\/DOC\/XML contents from normal URL link \/ downloading link.  Ensuring timely delivery of content without losing data, despite website configuration changes.  Identifying the website threshold limit to alert system administrators.      The Success:    Our solution on page monitoring and extraction rely on the powerful technique of rabbitmq and reds queue system to identify newly added contents \/ updated contents from the websites. It then extracts this into structured API with metadata like initial revision, current revision and previous revision.  As soon as a website is added into our Node Js platform with the required configuration, the extractor system crawls carefully to identify all the potential links of the website called spiders and stores them on to elastic search.  Based on the configured intervals, the extractor system looks for new \/ updated contents on the website, scraps it and updates the API which can be embedded into any platform like mobile or web.  For more information visit  www.thehub.ai"},{"nid":"1397","text_data":"KnowYourDay - AI Behavioral Analysis    The Overview:      KnowYourDay \u00a0is an Employee Performance Monitoring System which logs the activities of a user while predicting user behaviour and activity classification with Neural Network based Artificial Intelligence supported by algorithmic analysis. The platform creates detailed reports based on empirical observations and metric analysis.    Critically, the system uses aggregate data only to avoid the collection of any sensitive information.    Analysis can be grouped by projects, employees, departments, teams and tags. The goal of the platform is to support managers to understand the working patterns of their team, with more transparent &amp; flexible working systems, enabling business transformation insights to increase the productivity.    The Process:           The Requirement:    To collect the system logs, DNS, keystrokes, the file activities, time and application switch activities of a user in an encrypted cloud environment, we needed a lightweight endpoint for Max and Windows platform.  The platform must also perform behaviour analysis and activity classification based on the Neural Network algorithms to create an alert system triggers alerts when targets are met and when unusual behaviour is noticed in employees.  There was a need to have a centralised dashboard system for moderating endpoints, creating advanced real time timeline charts, performance comparison charts and billable reports. Also a remote push installer by which endpoints can be seamlessly installed over a network without a manual intervention.    The Challenge:      Getting root access and providing enough privileges to the endpoints for collecting DNS records.  Despite collecting various logs from the system in real time, CPU usage and Memory of the software must be optimized.  Auto updating the endpoints when an update is released without crashing or creating downtime for the app running in the background.  Maintaining and syncing the local database with the cloud storage whenever the internet connection is resumed.  Seamlessly install the end points across any scalable network through a single push button.  Understanding what the team is working on via Neural Network based categorisation of complex data with AI logical engine.      The Success:    The whole architecture is based on a non-blocking distributed code based with socket connected data flows (ES6, NodeJS, MongoDB and REDIS &amp; Swift for Mac). We collected the raw logs from the user machine and aggregate it to a usable format.  We had to do data reduction to optimise the data and fetch the data faster from the database. Besides, we also used REDIS to view the user\u2019s live log and to collect the user\u2019s log continuously without any downtime.  For more information visit  www.thehub.ai"},{"nid":"1398","text_data":"SparkElf - Realtime Digital Librarian    The Overview:      SparkElf \u00a0is based on an easy to use internal Information marketplace which allows simple personalised access to custom information streams including complex news queries, general feeds, API streams and internal created content.    The system allows every user to group and customise their information alerts by topic and schedule.    The streams and alerts can optionally be centrally managed for the end users by the internal communications team. The platform also allows multiple email templates which can be styled and customised for departmental and topic-based branding.    The Process:           The Requirement:    To build a fool proof alert system which can take input feeds in different formats and allow the users to subscribe to those feeds and receive alerts via email (and mobile when connected to the Reactions - Mobile Publishing Studio).    The Challenge:      Enabling moderators to add multiple email domains and allowing users of that domain to self-register.  Triggering only the latest feeds as alerts on scheduled time.  Feeds availability in case of white-labeled content.  Managing varied feeds with multiple alert options in a structured manner for the user.  The option to unsubscribe from a subscribed alert.      The Successs:    The whole architecture is based on a non-blocking distributed code based with socket connected data flows (ES6, NodeJs, MonoDB and ElasticSearch).  The goal of the architect was to facilitate the fastest possible information flow by minimising all and any pinch points and data propagation delays.  The design is based on a headless server approach which has the added benefit of allowing access via API in cases where it is desirable to feed the information into other corporate systems, such as mobile applications or microsites.  For more information visit  www.thehub.ai"},{"nid":"1399","text_data":"adappt Mobile Publishing Studio    The Overview:      adappt studio\u00a0 \u00a0is a content rendering platform for mobile devices. User will be able to feed in any type of content like RSS, editable content, either through forms, rich media or charts and it will be delivered on both IOS and Android devices in a structured tile format with features like push notification, favourite and content share to social network applications.    User has the facility to drag and drop, customise the tiles within the app as per their brand.    The theme of the platform is to enable the user to personalise the look and the feel of the app as and when they want as per their business needs.    The Process:           The Requirements:    To design a customised mobile app which can feed in from various type of inputs like XML\/RSS and in-house CMS portal, and can function in an offline mode while providing the ability to mark content as favourite\u00a0as well as option to share across social media applications. The app should also be able to render the content into various formats like charts, graphs, images and maps along with providing support for IPAD and tablet version.    The Challenge:      Rendering charts and integrating with external support like ESRI for displaying maps within the\u00a0mobile app.  To ensure all the pending articles in the push notification queue are rendered on-time to the subscribed user.  Drag and drop option for tiles, to customise the look and feel of the home screen.  Offline support using react-native to handle network failures.  Private and public key encryption for data exchange between mobile and web platform.      The Success:    Our robust backend platform supported by either SailsJS or Drupal has diverse features like managing content by adding, editing and updating from various inputs (external API in the form of JSON or content store) and facilitating with the revision history so that user has control over what they wish to render within the app.  Any changes that are made on the backend portal are converted into either JSON ( stored on amazon\u2019s S3 server ) or API to which the mobile app communicates by using token-based authentication.  Our react native mobile apps are written to enable users to theme their apps with their choice of colours, fonts, and size of the tiles.  For more information visit  www.thehub.ai"},{"nid":"1400","text_data":"Generate JSON    Generate Json    The Reaction Studio offers the generation of various types Jsons by which the information created and managed in the content management system and is sent to the React mobile application seamlessly.    Whats is Json ?    JSON: JavaScript Object Notation. When exchanging data between a browser and a server, the data can only be text. JSON is text, and we can convert any JavaScript object into JSON, and send JSON to the server.    Why use JSON?    Since the JSON format is text only, it can easily be sent to and from a server, and used as a data format by any programming language."},{"nid":"1402","text_data":"Menu Json  Menu json is like a backbone structure where the entire data depends on and all the data connected from various sections are connected. It uses a particular structure to communicate with other parts of the app, the admin interface is used to generate the menu json based on the content updated in the server."},{"nid":"1403","text_data":"Node JSON  Node Json holds the data for individual view 's content properties and data. All the individual content and its related images, tags will be maintained in the node json and like\u00a0menu json it uses a particular structure to display content in app."},{"nid":"1404","text_data":"Search JSON  Search JSON holds the key indexed data in the form of a JSON where the server use pretty neat algorithm to generate a search json structure from the created content. Search Json provides you lightning fast search feature"},{"nid":"1405","text_data":"Tags JSON  Tags JSON is used for relating contents and to group contents by categories. Each category is related to the main content and like others follow a specific structure"},{"nid":"1406","text_data":"Favorite  Sometimes you might come across an article you really want to read, but just don\u2019t have time to read it now or you really liked the article for future reference. There\u2019s an easy way to save those articles to read later, using \u2018Favorite\u2019 (heart icon) in each article. You can easily Favorite or Unfavorite an article. Also in footer menu you can access the list of favorited articles."},{"nid":"1407","text_data":"Share  This feature allows the user to share an article via popular social media Apps like Facebook, WhatsApp, Twitter and via email.    How to share?    The User can share any article by clicking on the share icon which is located beside the favourite icon. Upon clicking the share icon, the user would be prompted to select the App in which they would like to share the article. The link to the shared article along with the links to AppStore and PlayStore will be auto-generated in the social media App that the user have opened.    How to view the shared content?    By clicking on the link in the shared email\/message, it would open up the \u201c adappt studio \u201d app automatically and would take the user to that particular shared article screen."},{"nid":"1408","text_data":"Swipe Navigation  Swipe Navigation is a light app that allows you to swipe from the edge of your screen to execute many types of user's actions.  It is like pie controls but without any UI elements and is faster and easier to navigate"},{"nid":"1409","text_data":"Related Content  Related Content is used to associate \/ to show\u00a0similar contents or content which talks about similar topic\u00a0in app without needing to make search whole app. The related content information appears under the original content of the current screen. It created opportunities for the users to view or quickly access informations. The longer users are engaged, the more likely they are to complete conversion articles, such as read up the related topics, links and so on."},{"nid":"1410","text_data":"Breadcrumb  Breadcrumb is type of secondary navigation scheme that reveals the user\u2019s location in application. Breadcrumb navigation in real-world applications offer users a way to trace the path back to their original landing point. It\u2019s horizontally arranged links separated by the \u201cgreater than\u201d symbol (&gt;); the symbol indicates the level of that content relative to the screen beside it."},{"nid":"1411","text_data":"Global Search  Search Feature allows the user to search across the entire App based on the keyword\/phrase that user enters. The Search result displays list of article\u2019s instantly which matches the entered keyword with that keyword\u00a0highlighted. Upon clicking on the preview, it would take the user to the appropriate Article along with highlighted keywords."},{"nid":"1412","text_data":"Ckeditor and its features  This HTML text editor brings many of the powerful editing functions of known desktop editors like Word to the web. It loads faster and will perform less HTTP requests making it developer friendly.    Basic text styles    The basic styles package provides text formatting features such as bold, italic, underline, strikethrough and code.    Text alignment    It is possible to align the text as found in any word processor. You can choose from 'left', 'right', 'center' and 'justify    Different ways Images Uploading    There are several ways for the end user to insert images:    Pasting it from the clipboard.  Dragging a file from the file system.  Selecting it through a file system dialog.  Selecting it from a media management tool in your application."},{"nid":"1413","text_data":"Top Menu  A Top menu is similar to the Title of a book \" adappt studio \".\u00a0 You can have  only one Top menu  content type page in your application.  The Title field holds the name of the mobile application.  The image field in the Top menu content type is similar to that of a books outer cover and in our case, a mobile app\u00a0 homescreen background image.  In the text editor you can enter the Texts that should appear on the front cover page  E.g. \"Perfect Solution for Your Business\""},{"nid":"1414","text_data":"Menu Square  Menu square content types are used to navigate to important sections of the mobile applications which you may prefer and they will appear in squares.  How to create Menu square content types ?    Create a menu square content type page and provide its name in the \u201cTitle\u201d field.  Save the node and go to its view mode by clicking the \u201cView\u201d tab.  Navigate to the bottom of the page to find the \u201cAdd Child Page\u201d button and click it.  Now add your desired page which will appear in squares.  The desired page is where the user will be taken to when a square is clicked.  The desired page can be a \u201cContent page\u201d, \u201cMenu list\u201d page or \u201cContent - Menu List\u201d page.  You can add images for icons in the \u201cIcons\u201d field provided, which will appear in the square. Once completed, hit the \u201cSave\u201d button to save the changes in the node."},{"nid":"1415","text_data":"Menu List  Menu list content type is used to show the menu in the List form i.e one after each. The illustration is shown below. They are created in the same way as the Menu Squares."},{"nid":"1416","text_data":"Content With menu-list  You can create both Content and Menu listings in the same book page using this content  How to create Content-Menu List content types ?    Create a Content-Menu List content type page and provide its name in the \u201cTitle\u201d field.  Provide the text that should appear along with the List menu in the text editor. Save the node and go to its view mode by clicking the \u201cView\u201d tab.  Navigate to the bottom of the page to find the \u201cAdd Child Page\u201d button and click it.  Now add your desired page which will appear in the list.  The desired page is where the user will be taken to when an list is clicked.  The desired page can be a \u201cContent page\u201d, \u201cmenu list\u201d page or \u201ccontent - menu list\u201d page.  You can add images for icons in the \u201cIcons\u201d field provided which will appear in the square."},{"nid":"1417","text_data":"Content  As the name denotes, this content type is used to create basic informative pages of an mobile application that comprises of text\/images\/tables etc. You are provided with an text editor which has features of an default word processor. You can insert images, format the text , add tags and many. Once you have all of the information you can perform the click Save button at the bottom to save the changes made in the node."},{"nid":"1418","text_data":"Mirror Content  You can use an already created\/formatted node\u2019s template to create a new book page using this content type. The new page created will retain all of the settings\/styles of the original book page. By this way you don't need to re-create anything from scratch while wanting to create a page similar to the one already created.  You can call the original content using its \u201cTitle\u201d. Once the mirror content is saved, a new node is created having all the content, styles &amp; settings of the original node."},{"nid":"1419","text_data":"Ckeditor Settings"},{"nid":"1420","text_data":"Abbreviation  You can mark specific texts in the editor and mark as \u201cAbbreviations\u201d from the Styles dropdown menu or the abbreviation button \u201cA\u201d to make it look like the following    API    Application Programming Interface.  A set of subroutine definitions, protocols and tools for building application software.      CPU    Central Processing Unit.  the electronic circuitry within a computer that carries out the instructions of a computer program by performing the basic arithmetic, logical, control and input\/output (I\/O) operations specified by the instructions.      DOM    Document Object Model.  A cross-platform and language-independent application programming interface that treats an HTML document as a tree structure wherein each node is an object representing a part of the document      IDE    Integrated Development Environment.  A software application that provides programmers comprehensive facilities for software development.      MVC    Model-View-Controller.  An architectural pattern commonly used for developing user interfaces that divides an application into three interconnected parts.      NPM    Node Package Manager.  A package manager for JavaScript.      UI    User Interface.  The space where interactions between humans and machines occur."},{"nid":"1421","text_data":"Box Style  Similar like shades button a particular portion of texts can be highlighted within a box    Lorem Ipsum \u00a0is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed fermentum ante lacus, a maximus sapien consequat rhoncus. Vivamus varius tellus ac dapibus hendrerit. Sed in sem luctus, auctor tellus ut, faucibus sem. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Maecenas rhoncus rhoncus orci, et ultricies mauris scelerisque id. Duis et tortor eros.  Cras blandit congue dictum. Aenean eu venenatis elit. Aenean sodales pretium augue vel facilisis. Morbi risus nisl, vulputate eget hendrerit non, gravida at lacus. Morbi vel lectus nec metus lobortis convallis.\u00a0Pellentesque pharetra tincidunt varius. Proin molestie diam id gravida tempor. Nulla facilisi. Cras vitae fringilla leo. Pellentesque commodo consectetur feugiat. Fusce enim sapien, auctor a ex a, ullamcorper porta lacus."},{"nid":"1422","text_data":"Footer Notes  Footnotes can include anything from a citation to parenthetical information, outside sources, copyright permissions, background information, and anything in between, though certain style guides restrict when footnotes can be used..  You can mark the text in the editor and set as\u00a0 Footer notes \u00a0to see them appear at the bottom of the page.\u00a0  Ut vitae convallis metus, finibus iaculis metus. Donec congue dignissim ligula at scelerisque. Nam id aliquam lectus, at posuere mi."},{"nid":"1423","text_data":"Shade Blocks  A particular portions in a page of text can be differentiated\/highlighted using these shades functionalities. For example Blue \/ Green \/ Purple shade blocks etc\u2026  You can select the particular text which needs to be highlighted and press the \u201cBlue Shade\u201d button. Each shades are pictorially shown below    Blue Shade Block:    Quisque et malesuada sapien. Nulla at venenatis metus. Pellentesque commodo, lorem ac volutpat molestie, justo nulla dignissim dolor, mollis maximus urna sem at tortor. Morbi mollis eleifend massa in sollicitudin. Suspendisse ligula purus, tincidunt ut lorem nec, hendrerit tempus leo. Pellentesque pharetra tincidunt varius. Proin molestie diam id gravida tempor. Nulla facilisi. Cras vitae fringilla leo. Pellentesque commodo consectetur feugiat. Fusce enim sapien, auctor a ex a, ullamcorper porta lacus.    Green Shade Block:    Etiam tincidunt nec neque eu lobortis. Aliquam erat volutpat. Morbi egestas sodales massa, in tincidunt nisl dignissim non. Duis blandit lobortis ante, sed convallis mi fermentum tempor. Donec mattis orci sit amet ligula facilisis, quis iaculis dolor sodales. Nullam id libero ut erat porttitor efficitur.    Purple Shade Block:    Suspendisse potenti. Phasellus sodales efficitur faucibus. Cras sit amet pulvinar nunc. Nullam in nunc a leo blandit auctor sit amet vitae elit. Fusce dapibus sapien lorem, porta porta lacus convallis a. Curabitur justo lacus, fringilla nec imperdiet at, tempus suscipit tellus. Suspendisse vel purus sit amet dolor tincidunt posuere sit amet vel purus. Sed purus enim, cursus cursus ligula cursus, malesuada vestibulum diam. Quisque vel urna et risus varius suscipit."},{"nid":"1424","text_data":"Video Content    Know Your Day - Product Demo  from  TheHub.ai  on  Vimeo ."},{"nid":"1425","text_data":"Showcase  We\u2019ve got a wealth of technical expertise, knowledge and experience having developed numerous software solutions, Mobile Applications and Websites, including; multi-million pound systems and solutions for leading corporate organizations, NGOs, Councils to solutions for small to medium enterprises.  We run dedicated teams for our clients who act as an extension of their internal existing teams enabling them to add new skills to their existing team efficiently  We have mature teams with experience in Mobile, Desktop and console software applications. Our developers always have more than five years commercial programming experience and typically ten. They are generally programmatically multilingual and our teams cover MEAN Stack, Java, .Net, Php, Front-end JavaScript \/ Ajax, cocoa and c.  Using distributed communication and tracking technologies as well as online project management tracking software, you can keep in touch with our teams and on top of your project at all times.    Build your remote team with us\u00a0    click here"}]